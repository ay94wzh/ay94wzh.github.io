# 期末复习
## 01 introduction
1. 算法的有穷性：对于任何输入，经有穷次基本操作，都可以得到输出。例：
   1. Hailstone序列，无法证明有穷。
   2. while(rand()&1)理论上可能迭代任意多次，实际上期望为2次。
2. 注意关注各种算法的最坏情况。
3. 图灵机(q,c;d,L/R,p)含义：若当前状态为q，且当前字符为 c，则将当前字符改写为d，向左/右前进，转入p状态。
4. $\Omega$,$\Theta$,$O$依次增大。
5. ![级数](image.png)
   ![alt text](image-1.png)
   ![alt text](image-2.png)
6. ![alt text](image-3.png)
   ![alt text](image-4.png)
   ![alt text](image-5.png)
7. Master Theorem(针对分治递归$T(n)=aT(n/b)+O(g(n))$.)
   1. ![alt text](image-6.png)
   2. ![alt text](image-7.png)
   3. ![alt text](image-8.png)
   4. ![alt text](image-9.png)
8. 最大区间段总和
   1. 分而治之$O(nlogn)$。
   2. 减而治之，找非负后缀$O(n)$，相当于只扫描一遍。
9. 动态规划
   1. fib记忆法、颠倒计算方向。由指数优化为$O(n)$。
   2. 最长公共子序列：普通版由递归或记忆化版实现，递归基为三种基本情况，最坏情况$LCS(A[a],B[b])=C_{m+n-a-b}^{n-a}$,特别的，$m=n$时，最坏可达到$\Omega(2^n)$。迭代版则采用动态规划，只需要$O(m·n)$时间。用一个向量记录上一行，一个记录左边的元素，十分精巧的构造。
## 02 vector
1. 可扩充向量，上溢时采用容量加倍策略。基于分摊策略，容量加倍策略总体耗时$O(n)$,分摊后$O(1)$。
2. 单元素删除应视作区间删除的特例，相反则复杂度达到$O(n^2)$
3. 无序向量的查找，只能扫描，最好$O(1)$,最坏$O(n)$。
4. 无序向量的去重(dedup)，利用find与remove,查找成功一次，remove执行一次，复杂度$O(n)$。
5. 相邻逆序对的数目，可度量向量的紊乱程度。
6. 初步实现的有序向量需要去重。去重使用Two-Pointer Technique,懒惰却高效。
7. 二分查找版本A：普通的三段式递归，复杂度$O(logn)$,均摊到每次递归为$O(1)$。Fibonacci查找可以优化常数，这种方法常系数最小，黄金分割。
8. 二分查找B：相较于A，三段式划为两段式，性能更均衡(最好情况减弱，最坏情况优化)。
9. 二分查找C：![alt text](image-10.png)此种可将常数控制为$O(1.00·logn)$。
10. 插值查找：最坏$O(n)$,平均为$O(loglogn)$,相较究极体binSearch优势并不明显，且有乘除法运算。实际运用时先用插值查找，再用二分、顺序查找(逐步缩小范围)。
11. BubbleSort:提前终止版($hi$依次减小)，跳跃版($hi = last$)。最好$O(n)$，最坏$O(n^2)$。
12. MergeSort:$T(n)=2T(n/2)+g(n)$,故时间复杂度为$O(nlogn)$。缺点是需要对等规模的辅助空间。
13. BitMap：注意bit mask的运用，一般为$0X80>>(k\&0X07)$。test操作则将$M[k>>3]$与其按位与，set操作则与其或等于，clear操作则与其与等于后取反。
14. BitMap运用：小集合与大数据的问题，$n$个元素均取自$[0,m]$,$n>>m$，例如埃氏筛法。
15. BitMap的快速初始化，可使其运用达到$O(n)$时间。运用了精巧的校验环，参考讲义。
## 03 list
1. 选择排序：找到无序段中的最大节点，再经过一次交换。虽然总体复杂度仍为$O(n^2)$,但元素的移动远小于冒泡排序。
2. 插入排序：已经有序的情况最好$o(n)$，完全逆序的情况最坏$O(n^2)$,期望仍为$O(n^2)$。此为输入敏感型方法，但可以边输入数据边进行排序。
3.  MergeSort：复杂度同vector。
4.  Inversion：在序列中交换任意对逆序元素，逆序对总数必然减少，紧邻的减少1。通过MergeSort，可在$O(nlogn)$时间统计逆序对数。
5.  游标：不太懂。
## 04 stack + queue
1. 递归算法所需的空间，主要取决于递归深度。
2. 尾递归：最后一步操作是递归，会触发一连串的return，且返回地址相同。
3. 栈实例：进制转换，使用短除法+余商，可自低而高得出$\lambda$进制的各位。使用栈使高位先出。
4. 栈实例：括号匹配。凡是遇到“$($”则入栈，遇到“$)$”则出栈。最后栈空且不转负则匹配。
5. 中缀表达式：如果栈的顶部存在可优先计算的子表达式，则退栈，并使计算结果进栈。需要制定算符优先级表。令$p = priority$,若$p_{top}<p_{now}$，则先压入不计算，若$p_{top}>p_{now}$,则将栈顶计算符弹出计算后再压入。若$p_{top}=p_{now}$，则遇到右括号或结束哨兵。
6. 逆波兰表达式：数字则压入，算符则弹出相应数字计算后放回，无需考虑优先级。逆波兰表达式的构造：以运算符代替自己的右括号，清除左括号。
7. Stack Permutation：将$A$的顶元素弹出并压入$S$，将$S$的顶元素弹出并压入$B$。公式：$SP(n)=\frac{(2n)!}{(n+1)!·n!}$。注意禁形：对于任何$1 \leq i<j<k \leq n$,$[\dots,k,\dots,i,\dots,j\dots>$必定非混洗，此为充分必要条件。另一充要条件$[\dots,j+1,\dots,i,\dots,j\dots>$。有$O(n)$的算法逐个检视目标元素，可甄别禁形。方法如下：将原$B$的元素取出压入$B'$(即将$B$反向),$A$的元素压入$S'$,比较$S'$顶与$B'$顶，若相同则均pop，不同则继续压入；若最后$S'$中的元素为空则甄别成功。
8. Stack实例：直方图内最大矩形。递增则入栈，欲小的，则一个个出栈直到比其小为止。注意记录L与R，高度按栈顶元素高度计算。
9. Steap：p中每个元素，都是stack前缀中对应最大者。p可去重，即增加计数器。
10. 可用两个Stack模拟Queue，分摊策略可知复杂度为$O(3n)=O(n)$。
## 05 tree
1. 任意节点与根之间存在唯一路径。
2. 有根且有序的多叉树，均可转化并表示为二叉树。
3. 设度数为0，1，2的节点，各有$n_0$,$n_1$,$n_2$个。
   边数$e=n-1=n_1+2n_2$,1/2度节点各对应于1/2条入边。
   叶节点数$n_0=n_2+1$,注意$n_0$与$n_1$无关。
   总节点数$n=n_0+n_1+n_2=1+n_1+2n_2$
   以上为一些基本数量关系。
4. 满树：深度为$k$的节点，至多为$2^k$个。设高度为$h$，若$n=h+1$，退化为一条单链；若$n=2^{h+1}-1$，即为满二叉树。
5. 真二叉树：引入$n_1+2n_0$个外部节点，可使原有节点度数统一为2。例如红黑树。
6. 先序遍历：自上而下访问左边藤上节点，再自下而上遍历各右子树；各右子树的遍历彼此独立，各成一个子任务。
   1. 从根节点开始，沿左边藤下行（下行时已访问藤上节点），右孩子入栈（将来逆序出栈）。
   2. 出栈访问右节点，进入新循环，将弹出的右节点作为根，重复1。
7. 中序遍历：沿藤上节点自底而上访问藤上节点并立即访问对应的右子树
   1. 从根节点开始，沿左边藤下行，藤节点入栈。
   2. 出栈，立即访问弹出节点，再转向其右子树(`x=x->rc`)，重复1。
   3. 理解：每个节点出栈时，其左子树或不存在，或已经完全遍历，而右子树尚未入栈因此，要从其右孩子出发。
   4. 分摊分析：顺藤入栈看似是$O(n^2)$,实际上累计与`pop`一样多，故为$O(n)$。
   5. 直接后继：（向下）右左左左...；（向上）左左左...右；
8. 后序遍历：偏左入栈，即自顶而下反复检查顶节点，若栈顶结点有左孩子，则右孩子优先入栈，然后左孩子再入栈（出去时则为左-右-父）；无左孩子则只入右孩子；最后一次会入一个空节点，弹出即可。根节点首先入栈：
   1. 栈顶若不是当前出栈节点的父亲，而是其右兄弟（根节点除外），则对栈顶结点进行偏左入栈；若栈顶是当前结点的父亲，弹出即可。
   2. 注意，偏左入栈时，每个栈顶都要检查，直至到达其最左的叶子。
   3. 理解：每个结点出栈时，以其为根的子树已经完全遍历，而且若有右兄弟，则必在栈顶。
   4. 分摊分析与中序遍历相同。
   5. 应用：表达式树![alt text](image-11.png)
9. 层次遍历：与前三者区别，使用队而非栈。比较简单：根节点先入队，取出顶端节点之前，若有左孩子，左孩子入队，再右孩子入队。注意，入队是从尾入。
   1. 通过完全二叉树来考察辅助队的储存情况。![alt text](image-12.png) 
   2. 因此，辅助对列的规模单峰且对称，最大规模$\frac{n}{2}$(取上整)，且最大规模可能出现2次(允许1个单叶结点)
10. 二叉树重构：已知中序+先序或后序中的一种，可以重构二叉树。在一般情况下，知道先序和后序也能重构，但有特殊情况可能导致无法实现，如图![alt text](image-13.png)
11. 二叉树重构增强序列版：![alt text](image-14.png)
    ![alt text](image-15.png)
   注意，对先序，后续遍历，对任意子树均对应于一个子序列，且null结点比非null结点多1个！
12. Huffman树：常规而言，最优编码树使叶子均出现在倒数两层以内，否则交换节点。问题是，字符的出现频率差异较大。要使频率高的字符放在高处。
   1. Huffman的贪心策略：为每个字符创建一个单节点树，按频率对所有树排序，不断取频率最小的的两棵树合成新树，新树的频率为两子树之和。
   2. 双子性：i中实现的最优编码树为真二叉树，结点度数非2即0，否则将1度结点替换为其唯一孩子。
   3. 不唯一性：左右兄弟交换后子树频率不变，为消歧义可以要求左子树频率更低。
   4. 层次性：![alt text](image-16.png)
   说明：调整频率最小的叶子的位置，总频率不变，表明Huffman算法生成的是最优编码树之一。
   5. 优化：初始化时，将所有的树组织为一个优先级队列，取频率最低的两个树合成新树，插回队列，时间复杂度$O(nlogn)$。 
## 06 binary search tree
1. 中序性质：
   1. 顺序性：左，父，右从小到大有序(或其他次序)
   2. 单调性：采用中序遍历，遍历该树，得到的序列必然单调。
2. 查找：按大小往下走即可。
3. 插入：先借助查找找到位置(因为未找到会返回对应位置的引用)，修改即可。时间消耗于查找与更新树高，故均与树高成正比。
4. 删除：先查找定位，再删除与更新树高。删除情况可分为以下：
   1. 若度数为0或1，直接取代即可。
   2. 若度数为2，先找到当前结点的后继，交换元素，然后将要删除的元素所在的地方抹去(拖到菜市口再斩首)。值得注意的是，这种情况的菜市口度数必为0或1，故斩首时只需采用1.中的简单策略。
5. 平衡二叉搜索树：由上可知，操作的时间复杂度均与树高有关，因此需要平衡树高来节约时间。由于理想平衡条件过于苛刻，采用渐进平衡，高度为$O(logn)$而非严格$log_2n$。策略如下：![alt text](image-17.png)
6. AVL树：引入平衡因子$\lambda = h_l - h_r$,要求$|\lambda|\leq 1$。
   1. 树高证明：fib数列，高为h的AVL树节点数至少$S(h) = fib(h+3) - 1 $
   ![alt text](image-18.png)
   2. 失衡分析：插入可能导致从祖父开始的多个祖先失衡，删除可能导致从父亲开始的1个祖先失衡。
   3. 插入重平衡：失衡点复原后，高度与插入前一致。更重要的是，调整一次后，全树复原：
      1. 单旋：失衡点极其高孩子，高孙子（高孩子的高孩子），在一溜，在失衡点转一次即可。
      2. 双旋：拐了一下，故在高孩子处调整成一溜，然后同a操作。
   4. 删除重平衡，由以上分析知，只有一个失衡点。且失衡点复原后，高度未必与删除前一致，且失衡可能向上传播，可达$O(logn)$次调整。
      1. 单旋： 触发及操作与上述一致，但子树高度未必复原。
      2. 双旋：触发及操作与上述一致，但子树高度一定不复原。
   5. 3+4重构：将四种调整情况统一接口(g,p,v与从左到右四棵子树)。
   6. 综合评价：每种操作,复杂度最坏为$O(logn)$,但旋转操作(最多$O(logn)$次)常系数过大。
## 07 search tree application
1. Interval Tree(区间树)：stabbing query
   1. 创建一个集合$P$,$P$包含所有线段的端点(不重)
   2. 使$x_{mid}$为$P$集合在数量上的中间点
   3. 由此，所有线段可被分为三类：
      1. 尾端点在$x_{mid}$以左
      2. 首端点在$x_{mid}$以右
      3. 尾段不小于$x_{mid}$，且首端不大于$x_{mid}$
      4. $x_{mid}$成为根节点，再对左右集合进行相同的操作
   4. 查询： 注意结合图片
   ![alt text](image-19.png)
   5. 深度$O(logn)$,创建时间$O(nlogn)$，询问时间$O(r + logn)$，其中r为结果的数量(即捅到了r条线段)。
2. Segment Tree(线段树)
   1. 创建一个集合$P$,$P$包含所有线段的端点(可重，故数目$m$少于$2n$)
   2. 由此在数轴上定义了$m+1$个线段(例如$(P_i,P_i+1]$)
   3. 在ii中每个线段内，stabbing quer
   y的结果完全相同，时间仍为$O(r + logn)$
   4. 最坏情况：主要针对空间
   ![alt text](image-20.png)
   5. 贪心合并：可节约空间，使其达到$O(nlogn)$，创建也需$O(nlogn)$。
   ![alt text](image-21.png)
   ![alt text](image-22.png)
   6. 插入：递归策略，如果插入的线段完全覆盖了当前节点，则当前节点储存的线段数量+1，返回；否则，若与左孩子有交集，则向左递归；与右孩子有交集，则向右递归(同时进行)；时间为$O(logn)$
   7. 查询：根据大小向左走或向右走，直到叶才返回，报告沿途所有节点储存的线段；时间为$O(logn+r)$($r$代表report)
3. Range Query 1D：目标：在随机分布着点的线段上，任意划定一个区间，问这个区间中的点数量并枚举。如图实现，主要是二分查找：![alt text](image-23.png)
此为输出敏感型，时间复杂度为$O(1+r+logn)$
4. Range Query 2D：目标：在随机分布着点的平面上，任意划定一个区间，问这个区间中的点数量并枚举。
公式：对任意$R=(x_1,x_2] \times (y_1,y_2]$,$|R \cap P| = n(x_1,y_1)+n(x_2,y_2)-n(x_1,y_2)-n(x_2,y_1)$，其中，$n$表示该点与原点形成的矩形中点的数目。
复杂度上，需要$\theta(n_2)$的空间来储存$n(P)$，查询需要$O(logn)$的时间。
5. Multi-Level Search Tree 1D：
对于两个查询的边界，找到不大于其的最大叶子(图中标记为橙色)，然后找到他们最低的共同祖先(图中标记为红色)，然后记录从此共同祖先到橙色节点路径中所有未经过的子树。
![alt text](image-24.png)
查询复杂度$O(logn)$，预处理复杂度$O(nlogn)$，需要$O(n)$的空间进行储存。
6. Multi-Level Search Tree 2D：查询复杂度$O(r+log^2n)$，预处理复杂度$O(nlogn)$，需要$O(nlogn)$的空间进行储存。(使用了树中树策略)
7. Range Tree：用树中列表代替了树中树，使2D查询复杂度改进为$O(r+logn)$。这种改进对多维有效：![alt text](image-25.png)
8. kd-Tree：2D
   ![alt text](image-26.png)
预处理时间复杂度：$T(n)=2T(n/2)+O(n)=O(nlogn)$
空间复杂度：$1+2+\dots + 2^{logn} = O(n)$
查询时间:$Q(n)=2Q(n/4)+O(1)=O(\sqrt{n})$
对更高的维度：![alt text](image-27.png)
## advanced search tree
1. Spaly Tree :刚被访问过的数据，极有可能很快地再次被访问，因此让被访问的节点移动到上层以节约时间。节点一旦被访问，则被推送至根。采用双层伸展，可以降低时间复杂度。
   1. 所谓双层伸展，要使孙子成为爷爷。如果v,p,g不在一溜，转动方式与bbst相同；如果v,p,g在一溜，要先从爷爷开始转。如图：
   ![alt text](image-28.png)
   单次旋转最多出现一次，且在最后。分摊得，伸展操作只需要$O(logn)$的时间。
   2. 查找后，无论是否被找到，最后访问的对象会被伸展至根部，树结构改变。
   3. 插入如下，先查找，若找到则直接变成根，若没找到则根据v的大小放在根左上或右上。
   ![alt text](image-29.png)
   4. 删除：先查找e，将其伸展至根，并记录左子树L与右子树R，直接释放根节点。若右子树为空，则余树即为左子树；若右子树非空，则再在右子树中查找e，此操作必然失败，然而右子树中的最小节点会被伸展为右子树之根，且此时R的左子树必为空，此时可将L嫁接为其左子树，完成。
   5. 复杂度如下：![alt text](image-30.png)
2. B树：多级储存系统中使用B树，针对外部查找，可以大大减少I/O次数。充分利用外存的批量访问，每下降一层都以超级节点为单位，读入一组。在实际应用中视磁盘数据块大小而定。(cache:缓存)常用的数据，复制到更高层、更小的存储器中。找不到，才向更低层、更大的存储器索取
   1. 结构：每d代合并为超级节点，共有$m$路，$m-1$个关键码，即成为$m$阶B树。外部节点深度统一，约定为$h$，叶节点深度统一相等为$h-1$。除了根节点外，分枝数不能过少(多于$m/2$取上整)。
   2. 查找：在当前节点中顺序扫描，未找到则根据大小进入分枝(即模拟将下一块内存读入内存，在内存中顺序查找反而更快)。性能上，在每一深度至多I/O一次，故运行时间为$O(logn)$。
   3. 插入：若节点上溢，则新插入的节点上入父亲，并分裂。若上入后父亲也上溢，则如前做相同操作。至多至根节点，此时树长高一层。
   4. 删除：![alt text](image-31.png)
   ![alt text](image-32.png)
   若兄弟有多的，就顺着父亲转一个过来；若兄弟也正好在下界，就从父亲那里要一个胶水站在一起。同样的，第二种操作可能导致下溢上传。
3. 红黑树：对于BST而言，每次修改时只有结构有变处才需加锁，红黑树可以保证插入与删除操作结构变化量均为$O(1)$。这种性质可以用于版本管理，以实现$O(1)$重构。
   1. 结构：节点标记颜色，统一增设黑色外部节点null。根与null必为黑色，红色节点的父子必为黑色。引入黑高度，即黑色的真祖先的数目。null节点的黑深度必定相等。可视作一棵4阶B树。高度上，红黑树也是BBST,故高度为$O(logn)$。
   2. 插入：插入使要将$x=insert(e)$染红，以保证黑高度等性质不改变。可能出现的错误：$x$与$p$均为红色。按照$p$的兄弟$u$分为两种情况处理。要结合B树理解。
      1. $u$为黑： 收束后，即某三叉节点黑码不再居中，将颜色调整为$RBR$即可。
      2. $u$为红：![alt text](image-33.png)
      此种情况可能使B树上溢传递。如果g节点不幸上达树根，则强制转黑，整体黑高度+1。
   3. 删除：实际被删除处的节点度数只能为0或1(度数为2的节点会被交换到后继)。删除后可能导致双红条件和黑高度条件不满足。要分以下情况处理。
      1. $x$与其继承者$r$一黑一红，此情况很简单，略。
      2. $x$与其继承者$r$均为黑，恼火。BB-1(全局恢复),BB-2R(全局恢复),BB-2B(这种情况，当孩子的下溢修复后父节点必然继续下溢，因此要继续向上进行，且为局部恢复)，BB-3(此种情况处理后，要转化为BB-1或BB-2R,故也是全局恢复)
## dictionary
1. bucket：直接存放或间接指向一个词条。bucket arry = hashtable，希望保证哈希表的空间为$O(n)$,$n$为元素个数,$m$为hashtable容量。故需要一个散列函数$hash()：key \rightarrow entry$，将原始的数据映射到一个可控的集合中去。
2. collision：将两个不同元素映射到相同的哈希值，从而出现冲突。引入装填因子概念$\lambda = n/m$。通过降低$\lambda$，可以改善冲突程度，但无法杜绝。
3. hash function：希望能有确定性，快速性，尽量均匀(uniformity)分布。以下为几种基本方法。
   1. 除余法：$hash(key)=key \% M$,%M%选取素数时分布最充分，均匀。对于理想随机分布的序列，%M%是否为素数并不重要。但是，现实中的数据远非理想随机。缺陷为，存在不动点$hash(0)\equiv0$,且相邻关键码的散列地址必定相邻。
   2. MAD法：即multiply-add-divide，公式为$hash(key)=(a \times key+b)\% M$。
   3. 随机数法：一种为随机数发生器，实际上是伪随机数；一种为就地随机置乱，理想地将元素次序打乱(比如一串数字，随机交换顺序)，可以等概率地生成$n!$种排列。
   4. hashCode与多项式法：主要针对字符串，示例如下：![alt text](image-34.png)
4. 冲突策略：
   1. 开放散列：多槽位(桶单元可以储放多个冲突词条，空间既会浪费，又极有可能不足)；独立链(桶单元为一个列表，存放同义词，但动态分配极耗时，且空间不连续分布，系统缓存难以生效)策略。
   2. 封闭散列：主要是公共溢出区策略，单独开辟一块连续空间，发生冲突的词条，顺序存入此区域结构简单，但是一旦发生冲突最坏情况下，处理冲突词条所需的时间将正比于溢出区的规模。地址开放，任何桶都可接受任何词条，因此需要试探链。
   3. 懒惰删除：仅做标记，不对试探链做更多调整——此后，带标记的桶，角色因具体的操作而异，查找词条时，被视作“必不匹配的非空桶”，试探链在此得以延续，插入词条时，被视作“必然匹配的空闲桶”，可以用来存放新词条。
   4. rehashing：当$\lambda$大于一定值(通常为50%)，扩容。删除懒惰标记后，将每个非空桶都转入扩容后的新表。
   5. 平方试探：素数表长时，只要$\lambda$小于$0.5$，就一定能找出空位。且当表长为素数时，$n^2\%M$恰有$M/2$(取上整)种取值，且由试探链的前$M/2$项取遍。由此可见维护$\lambda$小于$0.5$的重要性。(可以反证法证明)
   6. 双向平方试探：正反向的子试探链恰好包含%M/2%个桶，且当表长取做$M=4k+3$的素数时，必然可以保证共计$M$个桶均互异。
   7. 双散列：另立一个散列函数，冲突时使用另外一个函数，不过这个函数仅用于确定偏移增量，如图：![alt text](image-35.png)
5. 桶排序：
   1. ![alt text](image-36.png)
   2. 应用：任意$n$个互异点将轴分为$n-1$段区间，求最长的一段。见下图：![alt text](image-37.png)
   3. 基数排序：![alt text](image-38.png)
   注意，这里n既是进制数，也是元素个数，所有元素都在$n^d$以内，以保证均可转化为$d$位的$n$进制数。
   4. 计数排序：有一堆有花色的牌，已经按照数字大小排好，想按照花色优先，数字递增的策略排序。![alt text](image-39.png)
   时间复杂度仍是$O(n)$。
6. 跳转表：每层抽稀(只有%1/2%概率长高)，因此总空间为$O(n)$
   1. 插入：找到位置后建塔即可
   2. 删除：从底层开始拆塔，拆光后只保留最底层的空表。
   3. 查询：![alt text](image-40.png)
   时间复杂度上，主要来源于横向跳转和纵向跳转。纵向跳转与层高有关，横向跳转与当前层的顶节点数有关。两者都是$O(logn)$的！
## priority queue
1. 逻辑上等同完全二叉树，物理上借助向量实现。对于第$i$个节点，父亲秩为$(i-1)/2$，左孩子$2i+1$，右孩子$2i+2$。$H[0]$必然是全局最大。
2. 插入：置尾，逐层上滤。
3. 删除：将尾部节点上置，逐层下滤。以上操作均为$O(logn)$
4. heapify：
   1. 从顶层建堆时需要不断插入，最坏时每个新入的节点都需上滤至根，然而总耗时也不过$O(nlogn)$
   2. 从底层建堆时，可视为不断合并堆$H_0$，$H_1$，以及节点$p$。只需要将两堆连成$p$的孩子，再对$p$下滤即可。每个内部节点调整的时间与高度(而非深度)有关。因此时间正比于所有节点高度的总和，为$O(n)$。
5. 堆排序：时间复杂度$O(nlogn)$，操作如图：![alt text](image-41.png)
   要借助向量的物理结构。
6. tourmanent：此为完全二叉树，可将所有叶节点视为参赛选手，内部节点为每场对决的胜者，树根总是全局冠军。
   1. 胜者树：移除根节点后，找到对应叶节点上溯的路径，并记为必败，顺其路径往上重新比较得到新的根。空间$O(n)$，构造时间$O(n)$，更新时只有对应路径上的祖先才需要比较，因此时间为$O(logn)$，如此，n轮比赛时间为$O(nlogn)$。选第k大的则是$O(klogn)$
   2. 败者树：内部节点反而记录败者，增设根节点之父记录冠军，移除胜者时，只需要进行父子间的比较，败者被记录在内部节点，胜者向上走直至根。相较于胜者树减少了交替迂回。
7. 左式堆：希望在$O(logn)$时间内实现堆的合并。类似二路归并的模式，将藤至于右侧，坨坨都吊在左边。所需时间正比于右侧的藤条长度。因此要控制好藤长。
   1. 引入$npl$，$npl(x)=1+min\{npl(lc(x)),npl(rc(x))\}$，即该节点到外部节点最近的距离。
   2. 希望控制$npl(lc(x)) >= npl(rc(x))$，因此所有节点的$npl$都是右孩子的+1。但并不意味着左子树的规模和高度更大。
   3. 右侧链：从根出发，一直沿着右侧分支前进，终点即为最浅的外部节点，记高度。如图：![alt text](image-42.png)
   4. 递归实现merge：如图，当$R_a$(即原a右子树与merge后的树)已经被返回后，要视情况交换$R_a$与$L_a$：![alt text](image-43.png)
   有前后两次交换处理。
   5. 插入与删除：插入即与单节点merge，删除就是把删除节点的左右子树merge。
## string
1. kmp算法：制作$next$查询表，在j处失配，就查询$next[j]$，确定向后移动的长度。快速右移，不会回退。注意头部有一精灵，与任何字符都匹配，记为-1位置。单次匹配概率越大（字符集越小），优势越明显
   1. 对$next$表的理解：最长自匹配，文本中有传递链![alt text](image-44.png)
   2. $next$表构造：![alt text](image-45.png)![alt text](image-46.png)
   3. 分摊分析：成功的对比覆盖整个T，失败的对比可分摊，总体仍为$O(n)$
   4. 改进：第j个不匹配后，会跳至第$next[j]$个，如果第j个等于第$next[j]$个，则会导致很多无效移动。![alt text](image-47.png) 
2. bad character策略：单次匹配概率越小，性能优势越明显 //大字母表： ASCII、 UniCode，P越长，这类移动的效果越明显
3. good suffix策略：略，太麻烦
4. 性能：![alt text](image-48.png)
5. kr算法(hash，将字符转化为数字)；键树。
## sorting+selection
1. quick sort：随机抽取轴点。有序序列中，所有元素皆为轴点。
   1. LUG版partition：从两侧向内部探，小入L，大入G，当lo = hi 时，将候选者嵌入LG之间成为轴点。各元素最多移动1次，因此为$O(n)$时间，$O(1)$辅助空间。
   2. 迭代与贪心策略：最好的情况，划分总是均衡的，递归深度为$O(logn)$；最坏的情况划分总是偏向一侧的，递归深度为$O(n)$。为了避免最坏情况，利用辅助栈进行迭代，大任务先入栈，小任务先出栈，可保证辅助栈空间不超过$O(logn)$。因此空间复杂度为$O(logn)$。时间性能分析如下：![alt text](image-49.png)
   3. 引入好轴点的概念，以研究递归深度：![alt text](image-50.png)
   ![alt text](image-51.png)
   ![alt text](image-52.png)
   4. 比较次数为$O(nlogn)$：可从递推分析和向后分析中证明。
   5. 对比其他排序，quick sort 是cache-friendly的。(见递归深度与辅助空间)
   6. DUP版partition：用于处理特殊情况：![alt text](image-53.png)
   ![alt text](image-54.png)
   7. LGU版partition：![alt text](image-55.png)
2. selection：要找第k大的元素
   1. 众数概念，注意要超过一半的相同元素才行：![alt text](image-56.png)
   ![alt text](image-57.png)
   2. 找两个有序向量的共同中位数：![alt text](image-58.png)
   3. quick select：与quick sort联系，当划分完毕后若基数所在位置大于k，则对基数左边区域进行划分操作，反之则对右边区域进行划分操作，直到基数所在位置等于k。时间复杂度的为$O(n)$。
   4. linear select：![alt text](image-59.png)